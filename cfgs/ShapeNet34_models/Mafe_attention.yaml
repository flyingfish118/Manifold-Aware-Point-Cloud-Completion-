optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0004,
  weight_decay : 0.0001
}}

scheduler:
  type: WarmUpLambdaLR
  kwargs:
    warmup_epochs: 5
    decay_step: 25
    lr_decay: 0.8
    lowest_decay: 0.01


bnmscheduler: {
  type: Lambda,
  kwargs: {
  decay_step: 25,
  bn_decay: 0.5,
  bn_momentum: 0.9,
  lowest_decay: 0.01
}}

dataset : {
  train : { _base_: cfgs/dataset_configs/ShapeNet-34.yaml, 
            others: {subset: 'train'}},
  val : { _base_: cfgs/dataset_configs/ShapeNet-34.yaml, 
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset_configs/ShapeNet-34.yaml, 
            others: {subset: 'test'}}} 
model : {
  NAME: Mafe_attention, num_pred: 8192, num_seeds: 1024, seed_fea: 128, dim_feat: 512, upscales: [1,2,4], l2_loss: 1}

loss : {
  sparse_loss_weight: 1.0,
  dense_loss_weight: 1.0,
  dz_weight: 1.0,
}
total_bs : 40
step_per_update : 1
max_epoch : 600

consider_metric: CDL1
