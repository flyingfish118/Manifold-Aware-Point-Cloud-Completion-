optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0003,
  weight_decay : 0.0001
}}

scheduler:
  type: WarmUpLambdaLR
  kwargs:
    warmup_epochs: 5
    decay_step: 23
    lr_decay: 0.8
    lowest_decay: 0.01


bnmscheduler: {
  type: Lambda,
  kwargs: {
  decay_step: 23,
  bn_decay: 0.5,
  bn_momentum: 0.9,
  lowest_decay: 0.01
}}


dataset : {
  train : { _base_: cfgs/dataset_configs/MVP.yaml, 
            others: {subset: 'train'}},
  val : { _base_: cfgs/dataset_configs/MVP.yaml, 
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset_configs/MVP.yaml, 
            others: {subset: 'test'}}}
            
model : {
  NAME: Mafe_attention, num_pred: 2048, num_seeds: 1024, seed_fea: 128, dim_feat: 1024, upscales: [1,1,2], l2_loss: 0}

loss : {
  sparse_loss_weight: 1.0,
  dense_loss_weight: 1.0,
  dz_weight: 1.0,
}
total_bs : 32
step_per_update : 1
max_epoch : 600

consider_metric: CDL1
